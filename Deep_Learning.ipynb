{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQWFusb7YycG368bTlbzAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agarwalsourabh55/Deep-learning/blob/deep_learning_dev/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VlIkxaNqNpFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf86420-9c69-4bfa-bc0d-28c3f107f1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.2105e-37, 0.0000e+00, 4.4842e-44])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "## Create the Empty Tensor\n",
        "x= torch.empty(3)\n",
        "print(x)\n",
        "x= torch.empty(2,3)\n",
        "x= torch.empty(2,2,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating torch with random values "
      ],
      "metadata": {
        "id": "U_gHJK42Oinh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w_vaoJtOu_D",
        "outputId": "6fae67dc-953f-456a-ff26-6e83fe950399"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7233,  0.0378, -0.9199],\n",
              "        [ 1.4418, -1.2958, -0.3074]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXlUmtq6O3c5",
        "outputId": "10d19825-34ca-4305-cccb-4037ef40b562"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Giving Specific Data type\n",
        "x.dtype  ## default float.32\n",
        "x= torch.ones(2,2,dtype=  torch.double)\n",
        "print(x.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNqvWFXiO5_H",
        "outputId": "199c9cd1-8326-42d6-cfa5-6a5502f20307"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.tensor([2.5,0.1])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZamghMHeO9Ii",
        "outputId": "cbd7f5cc-5b6e-45b8-8661-0f754ab4f393"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.randn(2,2)\n",
        "y= torch.randn(2,2)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEULN_BaPQPA",
        "outputId": "b6f2810f-d4fb-4758-f8cd-8a46d3e2ff1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4172,  0.2090],\n",
            "        [ 0.5973, -0.6693]])\n",
            "tensor([[ 1.6284, -1.3117],\n",
            "        [ 0.0707, -0.1412]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Addition\n",
        "z= x+y\n",
        "print(z) # Element wise addition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-r89odRPYv4",
        "outputId": "96736abd-8944-41ec-9aa3-303c98c55132"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2112, -1.1028],\n",
            "        [ 0.6680, -0.8105]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= torch.add(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5uerI1iPbJp",
        "outputId": "3015327b-2cc2-4459-a910-719b21dc0203"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2112, -1.1028],\n",
            "        [ 0.6680, -0.8105]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## inplace addition\n",
        "y.add_(x) ## will modify y\n",
        "\n",
        "## Every funciton that has _ aat the last will do the inplace operation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNIOv2RxPhj0",
        "outputId": "d64554c8-6688-434d-bf61-8d9a5f0ae0e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7940, -0.8938],\n",
              "        [ 1.2653, -1.4798]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## substaraction\n",
        "z= x-y\n",
        "z=torch.sub(x,y)\n"
      ],
      "metadata": {
        "id": "LaMV419kPmkl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Multipliacatino\n",
        "y.mul_(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb9e-tx5PzIr",
        "outputId": "2387cfee-3bf6-4a31-d876-c6a990f2fd06"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3312, -0.1868],\n",
              "        [ 0.7557,  0.9904]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## division \n",
        "torch.div(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks6SQbUxP2GP",
        "outputId": "0fd79724-4ddc-442f-dbdf-3bff91004f43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2595, -1.1188],\n",
              "        [ 0.7904, -0.6758]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## slicing Operations\n",
        "\n",
        "x= torch.rand(5,3)\n",
        "print(x[:,0])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfy3ZBxzP6iS",
        "outputId": "654b2331-20ef-4839-a5aa-21464ee15205"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3283, 0.7036, 0.6271, 0.6988, 0.4320])\n",
            "tensor([[0.3283, 0.1578, 0.4797],\n",
            "        [0.7036, 0.8818, 0.5780],\n",
            "        [0.6271, 0.4285, 0.4365],\n",
            "        [0.6988, 0.3112, 0.2248],\n",
            "        [0.4320, 0.7449, 0.2854]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfO_xn5XQDbj",
        "outputId": "0837aa5e-b910-4ab6-9a52-48079b851384"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5780)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Willge tthe actual value\n",
        "x[1,2].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOiQCNvDQNBj",
        "outputId": "d82b89ec-b2d3-41a0-b0c0-dbb94ae51f7f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5779715180397034"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## reshaping operation\n",
        "x= torch.rand(4,4)\n",
        "print(x)\n",
        "y= x.view(16)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSo6RkpJQUP3",
        "outputId": "05c5c9bb-2e1b-49bb-dacd-c26d58e62122"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2961, 0.9147, 0.7951, 0.4519],\n",
            "        [0.0882, 0.6399, 0.0094, 0.0505],\n",
            "        [0.4640, 0.1325, 0.9942, 0.0237],\n",
            "        [0.6641, 0.5004, 0.4337, 0.2985]])\n",
            "tensor([0.2961, 0.9147, 0.7951, 0.4519, 0.0882, 0.6399, 0.0094, 0.0505, 0.4640,\n",
            "        0.1325, 0.9942, 0.0237, 0.6641, 0.5004, 0.4337, 0.2985])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= x.view(-1,4)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzBKkJTAQezb",
        "outputId": "5d7c5766-92f0-41c7-fd6c-81b25152ae8d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#converting numpy to tensor\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCApdPIlQuKc",
        "outputId": "602c1812-8fc4-4f7a-eebb-ed65f7e9ce75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGErVxkZQwwO",
        "outputId": "d7787413-1781-4cd2-cb2c-1b0476ba03a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Also added +1 to the b also..because they point to the same memory location\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjD1V4aqR5IS",
        "outputId": "a436b26b-83ac-4612-9492-4091d041e532"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.ones(5)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMTL5kLQR7pJ",
        "outputId": "67b76793-348f-4b40-ecc8-febd41996a0b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b= torch.from_numpy(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eugmjo1QSEuf",
        "outputId": "4a94aa37-8695-4685-845c-eb61320494b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a+=1"
      ],
      "metadata": {
        "id": "dBieziy7SJ5D"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This happen only when you have tensor on the GPU\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bh6X80WSNZ0",
        "outputId": "22d39ebe-9311-4599-c7b4-4640fb71227d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## checking cuda availability\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = torch.ones(5,device = device)\n",
        "  y = torch.ones(5)\n",
        "  y= y.to(device)\n",
        "\n",
        "  z= x+y\n",
        "  z.numpy()## will return error because numpy only handle CPU tensors not GPU\n",
        "  z = z.to(\"cpu\")\n",
        "else:\n",
        "  print(\"not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCa2eHRASRAs",
        "outputId": "4a91bcb7-b587-4336-8731-1d3bad68ba13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.ones(5,requires_grad = True)  ## tellthe pytroch that it will nees to calculate the gradients\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tl_XkmaSszh",
        "outputId": "69792fa7-fdb6-49aa-892d-b08aab03fa00"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Autgrad package and Calculating Gradients\n",
        "import torch\n",
        "x= torch.randn(3,requires_grad = True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R26Lr3KrTGsd",
        "outputId": "cfa6e09c-620d-4662-ea14-155f5cb1edb8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9422, 1.3274, 0.2494], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2 ## will create the computational graph    x                      this is forward pass\n",
        "                                                      # +   y\n",
        "                                                  # 2\n",
        "## pytorch will automatically create the function that will later use to creat the backpropogation function_name = Addbackward\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGTBGePHTk6C",
        "outputId": "5a0268e5-b41f-4336-a353-d9791f021d30"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.9422, 3.3274, 2.2494], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= y*y*2\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdEc9_ExUH5q",
        "outputId": "1afb4a40-7dd2-41de-c0b5-a1299da9d391"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([17.3136, 22.1426, 10.1199], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z= z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKsTgdLUR7r",
        "outputId": "45e11516-c284-408f-dc55-c629d3d33d5c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16.5254, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward() ## tocalulat ethe gradient of z with respect tox\n",
        "print(x.grad)  ## x store that gradient\n",
        "## in backward it will creat the vector of jacobian matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L86WutxUUSI",
        "outputId": "556fc4a1-dcbe-4418-a931-b47e64fbaa78"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.9230, 4.4365, 2.9992])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.randn(3,requires_grad= True)\n",
        "y= x+2\n",
        "z= y*y*2\n",
        "\n",
        "# z.backward()\n",
        "# print(x.grad)# this will give error need to add one line \n",
        "\n",
        "v = torch.tensor([0.1,1.0,0.001], dtype = torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH71CtgCUcVG",
        "outputId": "1d34e456-f96c-49dc-93e9-1b378c1e3dc4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8598, 5.9732, 0.0117])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Call the requires_grad_(False)\n",
        "## x.detach() ## create new tensor that doesn't reauire gradieent\n",
        "## with torch.no_grad():\n",
        "\n",
        "x= torch.randn(3,requires_grad = True)\n",
        "print(x)\n",
        "x.requires_grad_(False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZ_wFLGVfuh",
        "outputId": "d2e62ca1-bf41-41f3-b920-2b6ee7e558f3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.5585, -0.6175, -1.0777], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.5585, -0.6175, -1.0777])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwJgaHGtWSsr",
        "outputId": "b66c3901-3fb4-4af9-a0e8-e4c656e31d82"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.5585, -0.6175, -1.0777])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.randn(3,requires_grad = True)\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y) ## y don't have gradient function\n",
        "print(x) ## x has gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alRzt9e8WdsY",
        "outputId": "b1bb8afc-e33d-40ac-bb1d-40e15e1d0b58"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.6250, 2.2028, 0.5080])\n",
            "tensor([ 0.6250,  0.2028, -1.4920], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Whenever we call the backward function the value will be accumulated in the x"
      ],
      "metadata": {
        "id": "srDgqWnNWjsE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad = True)\n",
        "for epoch in range(2):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()  # need to add this to prevent gradient to calculate on every iteration\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOLrKdW4Wk0V",
        "outputId": "35470fa2-37d4-4334-a857-ba02b4d9ff3f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad = True)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD([weights] , lr = 0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "lIbOgwSVYYcv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad = True)\n",
        "\n",
        "## these are autograd package\n",
        "# z.backward()\n",
        "# weights.grad.zero_()"
      ],
      "metadata": {
        "id": "-Wfy6ZlEYuri"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Backpropogation\n",
        "\n",
        "## forward pass: compute Loss\n",
        "## Compute local gradients\n",
        "## Backward pass: Compute dLoss / dWeights using the Chain Rule\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0,requires_grad = True)\n",
        "\n",
        "## Forward pass and compute the loss\n",
        "y_hat = w*x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "### update weights\n",
        "### next forward and backwars\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4893Siicd9Lm",
        "outputId": "d367e75c-600e-4ed4-d324-c37c0df41082"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "X = np.array([1,2,3,4],dtype= np.float32)\n",
        "Y  = np.array([2,4,6,8],dtype = np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# Model Prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "## loss = MSE\n",
        "def loss(y,y_predicted):\n",
        "  return((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "# MSE =1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (w*x -y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  ## gradients\n",
        "  dw = gradient(X,Y,y_pred)\n",
        "\n",
        "  # update weights\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after Training : f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JppsQ1WiIEw",
        "outputId": "5c9cc757-ee7b-498c-9c7f-70fbcd379508"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 2: w = 1.680, loss = 4.79999924\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 4: w = 1.949, loss = 0.12288000\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 6: w = 1.992, loss = 0.00314574\n",
            "epoch 7: w = 1.997, loss = 0.00050331\n",
            "epoch 8: w = 1.999, loss = 0.00008053\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 10: w = 2.000, loss = 0.00000206\n",
            "Prediction after Training : f(5) = 9.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1,2,3,4],dtype= torch.float32)\n",
        "Y  =torch.tensor([2,4,6,8],dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad= True)\n",
        "\n",
        "# Model Prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "## loss = MSE\n",
        "def loss(y,y_predicted):\n",
        "  return((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "# MSE =1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (w*x -y)\n",
        "\n",
        "# def gradient(x,y,y_predicted):\n",
        "#   return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  ## gradients\n",
        "  # dw = gradient(X,Y,y_pred)\n",
        "  l.backward() ## calulate the gradient of loss dl/dw\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  ## empty zero gradient\n",
        "  w.grad.zero_()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after Training : f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdmpg6YuHWnq",
        "outputId": "addc3d31-d3b0-4941-df6b-5fea2ec0a862"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 2: w = 0.555, loss = 21.67499924\n",
            "epoch 3: w = 0.772, loss = 15.66018772\n",
            "epoch 4: w = 0.956, loss = 11.31448650\n",
            "epoch 5: w = 1.113, loss = 8.17471695\n",
            "epoch 6: w = 1.246, loss = 5.90623236\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 8: w = 1.455, loss = 3.08308983\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 10: w = 1.606, loss = 1.60939169\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 12: w = 1.716, loss = 0.84011245\n",
            "epoch 13: w = 1.758, loss = 0.60698116\n",
            "epoch 14: w = 1.794, loss = 0.43854395\n",
            "epoch 15: w = 1.825, loss = 0.31684780\n",
            "epoch 16: w = 1.851, loss = 0.22892261\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 18: w = 1.893, loss = 0.11949898\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "epoch 20: w = 1.922, loss = 0.06237914\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 22: w = 1.944, loss = 0.03256231\n",
            "epoch 23: w = 1.952, loss = 0.02352631\n",
            "epoch 24: w = 1.960, loss = 0.01699772\n",
            "epoch 25: w = 1.966, loss = 0.01228084\n",
            "epoch 26: w = 1.971, loss = 0.00887291\n",
            "epoch 27: w = 1.975, loss = 0.00641066\n",
            "epoch 28: w = 1.979, loss = 0.00463169\n",
            "epoch 29: w = 1.982, loss = 0.00334642\n",
            "epoch 30: w = 1.985, loss = 0.00241778\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 32: w = 1.989, loss = 0.00126211\n",
            "epoch 33: w = 1.991, loss = 0.00091188\n",
            "epoch 34: w = 1.992, loss = 0.00065882\n",
            "epoch 35: w = 1.993, loss = 0.00047601\n",
            "epoch 36: w = 1.994, loss = 0.00034392\n",
            "epoch 37: w = 1.995, loss = 0.00024848\n",
            "epoch 38: w = 1.996, loss = 0.00017952\n",
            "epoch 39: w = 1.996, loss = 0.00012971\n",
            "epoch 40: w = 1.997, loss = 0.00009371\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 42: w = 1.998, loss = 0.00004891\n",
            "epoch 43: w = 1.998, loss = 0.00003534\n",
            "epoch 44: w = 1.998, loss = 0.00002553\n",
            "epoch 45: w = 1.999, loss = 0.00001845\n",
            "epoch 46: w = 1.999, loss = 0.00001333\n",
            "epoch 47: w = 1.999, loss = 0.00000963\n",
            "epoch 48: w = 1.999, loss = 0.00000696\n",
            "epoch 49: w = 1.999, loss = 0.00000503\n",
            "epoch 50: w = 1.999, loss = 0.00000363\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 52: w = 2.000, loss = 0.00000190\n",
            "epoch 53: w = 2.000, loss = 0.00000137\n",
            "epoch 54: w = 2.000, loss = 0.00000099\n",
            "epoch 55: w = 2.000, loss = 0.00000071\n",
            "epoch 56: w = 2.000, loss = 0.00000052\n",
            "epoch 57: w = 2.000, loss = 0.00000037\n",
            "epoch 58: w = 2.000, loss = 0.00000027\n",
            "epoch 59: w = 2.000, loss = 0.00000019\n",
            "epoch 60: w = 2.000, loss = 0.00000014\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 62: w = 2.000, loss = 0.00000007\n",
            "epoch 63: w = 2.000, loss = 0.00000005\n",
            "epoch 64: w = 2.000, loss = 0.00000004\n",
            "epoch 65: w = 2.000, loss = 0.00000003\n",
            "epoch 66: w = 2.000, loss = 0.00000002\n",
            "epoch 67: w = 2.000, loss = 0.00000001\n",
            "epoch 68: w = 2.000, loss = 0.00000001\n",
            "epoch 69: w = 2.000, loss = 0.00000001\n",
            "epoch 70: w = 2.000, loss = 0.00000001\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 72: w = 2.000, loss = 0.00000000\n",
            "epoch 73: w = 2.000, loss = 0.00000000\n",
            "epoch 74: w = 2.000, loss = 0.00000000\n",
            "epoch 75: w = 2.000, loss = 0.00000000\n",
            "epoch 76: w = 2.000, loss = 0.00000000\n",
            "epoch 77: w = 2.000, loss = 0.00000000\n",
            "epoch 78: w = 2.000, loss = 0.00000000\n",
            "epoch 79: w = 2.000, loss = 0.00000000\n",
            "epoch 80: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 82: w = 2.000, loss = 0.00000000\n",
            "epoch 83: w = 2.000, loss = 0.00000000\n",
            "epoch 84: w = 2.000, loss = 0.00000000\n",
            "epoch 85: w = 2.000, loss = 0.00000000\n",
            "epoch 86: w = 2.000, loss = 0.00000000\n",
            "epoch 87: w = 2.000, loss = 0.00000000\n",
            "epoch 88: w = 2.000, loss = 0.00000000\n",
            "epoch 89: w = 2.000, loss = 0.00000000\n",
            "epoch 90: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "epoch 92: w = 2.000, loss = 0.00000000\n",
            "epoch 93: w = 2.000, loss = 0.00000000\n",
            "epoch 94: w = 2.000, loss = 0.00000000\n",
            "epoch 95: w = 2.000, loss = 0.00000000\n",
            "epoch 96: w = 2.000, loss = 0.00000000\n",
            "epoch 97: w = 2.000, loss = 0.00000000\n",
            "epoch 98: w = 2.000, loss = 0.00000000\n",
            "epoch 99: w = 2.000, loss = 0.00000000\n",
            "epoch 100: w = 2.000, loss = 0.00000000\n",
            "Prediction after Training : f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove manuall work from previous cell\n",
        "# 1) Design Model (input,output_size,forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#  - forward pass: compute predictions\n",
        "#  - backward pass: gradients\n",
        "#  - update weights\n",
        "#   iterate the couple of times for the best result\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([ [1]\n",
        "                  ,[2]\n",
        "                  ,[3]\n",
        "                  ,[4]],dtype= torch.float32)\n",
        "Y  =torch.tensor([ [2]\n",
        "                  ,[4]\n",
        "                  ,[6]\n",
        "                  ,[8]],dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5],dtype = torch.float32)\n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "print(n_samples,n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# model = nn.Linear(input_size,output_size)\n",
        "\n",
        "# OR\n",
        "## For custom Model\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self,input_dim, output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    self.lin = nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size , output_size)\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  ## gradients\n",
        "  # dw = gradient(X,Y,y_pred)\n",
        "  l.backward() ## calulate the gradient of loss dl/dw\n",
        "\n",
        "  # update weights\n",
        "  # with torch.no_grad():\n",
        "  #   w -= learning_rate * w.grad\n",
        "  optimizer.step()\n",
        "  ## empty zero gradient\n",
        "  # w.grad.zero_()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 10 ==0:\n",
        "    [w,b]= model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after Training : f(5) = {model(X_test).item():.3f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erhAmB-tIo1k",
        "outputId": "ab7a1717-fdf6-445e-c1c0-ccf128937abe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training: f(5) = -2.793\n",
            "epoch 1: w = -0.181, loss = 48.96280289\n",
            "epoch 11: w = 1.428, loss = 1.36606526\n",
            "epoch 21: w = 1.693, loss = 0.12884462\n",
            "epoch 31: w = 1.742, loss = 0.09139267\n",
            "epoch 41: w = 1.756, loss = 0.08529816\n",
            "epoch 51: w = 1.765, loss = 0.08031323\n",
            "epoch 61: w = 1.772, loss = 0.07563814\n",
            "epoch 71: w = 1.779, loss = 0.07123555\n",
            "epoch 81: w = 1.785, loss = 0.06708927\n",
            "epoch 91: w = 1.791, loss = 0.06318435\n",
            "Prediction after Training : f(5) = 9.582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mcpmlrxHK70A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}